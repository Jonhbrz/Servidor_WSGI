[{"content":"En esta sección veremos cómo ajustar Waitress para mejorar rendimiento y estabilidad en producción.\n1. Ejecutar la aplicación con parámetros waitress-serve \\ --listen=0.0.0.0:8000 \\ --threads=8 \\ --asyncore-use-poll \\ main:app 2. Parámetros recomendados Parámetro Descripción --threads Número de threads por worker. 4–8 suele ser suficiente. --listen Dirección IP y puerto donde escuchar. --asyncore-use-poll Mayor compatibilidad en contenedores. 3. Uso desde Docker CMD [\u0026#34;waitress-serve\u0026#34;, \u0026#34;--listen=0.0.0.0:8000\u0026#34;, \u0026#34;main:app\u0026#34;] Waitress funciona perfectamente dentro de contenedores debido a su simplicidad y estabilidad.\n4. Logs Para ver logs en un contenedor:\ndocker logs api1 Esto te permite verificar la actividad y detectar errores.\n","permalink":"http://localhost:1313/Servidor_WSGI/configuracion/","summary":"\u003cp\u003eEn esta sección veremos cómo ajustar Waitress para mejorar rendimiento y estabilidad en producción.\u003c/p\u003e\n\u003ch2 id=\"1-ejecutar-la-aplicación-con-parámetros\"\u003e1. Ejecutar la aplicación con parámetros\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ewaitress-serve \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --listen\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e0.0.0.0:8000 \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --threads\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e8\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  --asyncore-use-poll \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e  main:app\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"2-parámetros-recomendados\"\u003e2. Parámetros recomendados\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eParámetro\u003c/th\u003e\n          \u003cth\u003eDescripción\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ccode\u003e--threads\u003c/code\u003e\u003c/td\u003e\n          \u003ctd\u003eNúmero de threads por worker. 4–8 suele ser suficiente.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ccode\u003e--listen\u003c/code\u003e\u003c/td\u003e\n          \u003ctd\u003eDirección IP y puerto donde escuchar.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ccode\u003e--asyncore-use-poll\u003c/code\u003e\u003c/td\u003e\n          \u003ctd\u003eMayor compatibilidad en contenedores.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"3-uso-desde-docker\"\u003e3. Uso desde Docker\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-dockerfile\" data-lang=\"dockerfile\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eCMD\u003c/span\u003e [\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;waitress-serve\u0026#34;\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;--listen=0.0.0.0:8000\u0026#34;\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;main:app\u0026#34;\u003c/span\u003e]\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eWaitress funciona perfectamente dentro de contenedores debido a su simplicidad y estabilidad.\u003c/p\u003e","title":"Configuración de Waitress"},{"content":"En esta sección verás el despliegue completo en producción utilizando:\nFlask + Waitress (backend WSGI) Dockerfile (para build de la API) Docker Compose (para levantar varias instancias) Nginx como reverse proxy y balanceador de carga Múltiples contenedores ejecutando la misma API Hugo para documentar el proyecto Esta arquitectura permite que la API sea accedida desde múltiples dispositivos de forma estable y escalable.\n1. Estructura del proyecto Tu proyecto está organizado así:\nSERVIDOR-WAITRESS/\r├─ api/\r│ ├─ Dockerfile\r│ ├─ main.py\r│ ├─ pyproject.toml\r│ └─ uv.lock\r├─ docs/ ← sitio Hugo para documentación\r├─ nginx/\r│ └─ nginx.conf\r└─ docker-compose.yml 2. Dockerfile de la API El Dockerfile se encarga de:\nInstalar dependencias Copiar el código Lanzar Waitress en el puerto 8000 FROM python:3.12-slim ENV PYTHONDONTWRITEBYTECODE=1 ENV PYTHONUNBUFFERED=1 WORKDIR /app COPY pyproject.toml ./ RUN pip install --upgrade pip setuptools wheel \u0026amp;\u0026amp; pip install waitress \u0026amp;\u0026amp; pip install -e . COPY . . EXPOSE 8000 CMD [\u0026#34;waitress-serve\u0026#34;, \u0026#34;--listen=0.0.0.0:8000\u0026#34;, \u0026#34;main:app\u0026#34;] 3. docker-compose.yml con múltiples instancias Aquí levantas dos contenedores idénticos tictactoe1 y tictactoe2, ambos corriendo la API por Waitress.\nLuego Nginx se encarga del balanceo.\nversion: \u0026#34;3.8\u0026#34; services: tictactoe1: build: ./api container_name: tictactoe1 restart: always networks: - tictactoe-net expose: - \u0026#34;8000\u0026#34; tictactoe2: build: ./api container_name: tictactoe2 restart: always networks: - tictactoe-net expose: - \u0026#34;8000\u0026#34; nginx: image: nginx:latest container_name: nginx_tictactoe restart: always volumes: - ./nginx/nginx.conf:/etc/nginx/nginx.conf ports: - \u0026#34;9000:80\u0026#34; depends_on: - tictactoe1 - tictactoe2 networks: - tictactoe-net networks: tictactoe-net: driver: bridge 4. Configuración de Nginx (nginx.conf) Nginx actúa como:\nReverse Proxy Balanceador de carga Punto de entrada externo (puerto 9000) worker_processes 1; events { worker_connections 1024; } http { upstream tictactoe_upstream { ip_hash; server tictactoe1:8000; server tictactoe2:8000; } server { listen 80; location / { proxy_pass http://tictactoe_upstream; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; } } } ip_hash asegura que cada cliente siempre vaya al mismo backend (ideal para sesiones persistentes).\n5. Levantar todo el sistema Desde la carpeta raíz del proyecto:\ndocker-compose build docker-compose up -d Comprobar contenedores:\ndocker ps Todos deben aparecer como Up.\n6. Probar la API desde el navegador o curl Registrar un device:\ncurl -X POST http://localhost:9000/devices Ver dispositivos:\ncurl http://localhost:9000/devices Nginx distribuirá las peticiones entre tictactoe1 y tictactoe2.\n7. Confirmar balanceo de carga Ver logs:\ndocker logs tictactoe1 docker logs tictactoe2 Ambos deben recibir tráfico.\n","permalink":"http://localhost:1313/Servidor_WSGI/despliegue/","summary":"\u003cp\u003eEn esta sección verás el \u003cstrong\u003edespliegue completo en producción\u003c/strong\u003e utilizando:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFlask\u003c/strong\u003e + \u003cstrong\u003eWaitress\u003c/strong\u003e (backend WSGI)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDockerfile\u003c/strong\u003e (para build de la API)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDocker Compose\u003c/strong\u003e (para levantar varias instancias)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNginx\u003c/strong\u003e como reverse proxy y balanceador de carga\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMúltiples contenedores\u003c/strong\u003e ejecutando la misma API\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHugo\u003c/strong\u003e para documentar el proyecto\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEsta arquitectura permite que la API sea accedida desde múltiples dispositivos de forma estable y escalable.\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"1-estructura-del-proyecto\"\u003e1. Estructura del proyecto\u003c/h1\u003e\n\u003cp\u003eTu proyecto está organizado así:\u003c/p\u003e","title":"Despliegue Final con Nginx y Waitress (Múltiples Contenedores)"},{"content":"En esta sección veremos cómo se instala Waitress dentro del contenedor Docker que ejecuta la API.\nWaitress es el servidor WSGI que utilizamos para servir la aplicación Flask en producción.\n1. Instalación de Waitress mediante Docker En este proyecto, Waitress no se instala manualmente en el sistema, sino que se incluye directamente dentro del Dockerfile del servicio API.\nEsto garantiza:\nUn entorno limpio y reproducible Independencia del sistema operativo Misma configuración en todas las instancias (tictactoe1, tictactoe2, etc.) 2. Dockerfile con instalación automática de dependencias El paquete Waitress se instala dentro del contenedor utilizando pip install.\nEste es el bloque relevante del Dockerfile:\nRUN pip install --upgrade pip setuptools wheel \u0026amp;\u0026amp; \\ pip install waitress \u0026amp;\u0026amp; \\ pip install -e . Aquí ocurre lo siguiente:\nSe actualiza pip y herramientas base Se instala Waitress Se instalan las dependencias del proyecto (definidas en pyproject.toml) 3. Ejecución de la API con Waitress dentro del contenedor Waitress se utiliza como entrypoint del contenedor:\nCMD [\u0026#34;waitress-serve\u0026#34;, \u0026#34;--listen=0.0.0.0:8000\u0026#34;, \u0026#34;main:app\u0026#34;] Esto significa:\nLa API escucha en el puerto 8000 dentro del contenedor Waitress sirve la aplicación Flask disponible en main.py bajo el nombre app Todo está totalmente automatizado con Docker 4. Levantar la aplicación ya configurada con Waitress Para construir e iniciar los contenedores:\ndocker-compose build docker-compose up -d Esto lanza:\nDos instancias de la API (tictactoe1 y tictactoe2) Cada una ejecutada por Waitress Nginx como reverse proxy sobre ellas Resultado final A diferencia de una instalación manual en el sistema, aquí:\nNo es necesario configurar entornos virtuales No debes instalar Waitress en tu máquina No debes ejecutar waitress-serve tú mismo Todo ocurre automáticamente dentro de los contenedores, garantizando un entorno limpio, escalable y replicable.\n","permalink":"http://localhost:1313/Servidor_WSGI/instalacion/","summary":"\u003cp\u003eEn esta sección veremos cómo se instala \u003cstrong\u003eWaitress\u003c/strong\u003e dentro del contenedor Docker que ejecuta la API.\u003cbr\u003e\nWaitress es el servidor WSGI que utilizamos para servir la aplicación Flask en producción.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-instalación-de-waitress-mediante-docker\"\u003e1. Instalación de Waitress mediante Docker\u003c/h2\u003e\n\u003cp\u003eEn este proyecto, Waitress \u003cstrong\u003eno se instala manualmente en el sistema\u003c/strong\u003e, sino que se incluye directamente dentro del \u003cstrong\u003eDockerfile\u003c/strong\u003e del servicio API.\u003c/p\u003e\n\u003cp\u003eEsto garantiza:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUn entorno limpio y reproducible\u003c/li\u003e\n\u003cli\u003eIndependencia del sistema operativo\u003c/li\u003e\n\u003cli\u003eMisma configuración en todas las instancias (tictactoe1, tictactoe2, etc.)\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-dockerfile-con-instalación-automática-de-dependencias\"\u003e2. Dockerfile con instalación automática de dependencias\u003c/h2\u003e\n\u003cp\u003eEl paquete Waitress se instala dentro del contenedor utilizando \u003ccode\u003epip install\u003c/code\u003e.\u003cbr\u003e\nEste es el bloque relevante del Dockerfile:\u003c/p\u003e","title":"Instalación Básica de Waitress"},{"content":"Bienvenido a la documentación del proyecto TicTacToe API, un sistema que combina:\nFlask + Waitress como servidor backend. Docker + Docker Compose para encapsular la aplicación. Nginx como reverse proxy y balanceador de carga. Hugo para documentar todo el proceso. El objetivo de este proyecto es ejecutar una API de forma escalable desde múltiples dispositivos, aprovechando la potencia de Docker y la estabilidad de Waitress como servidor WSGI.\nAquí aprenderás:\nCómo instalar Waitress en un entorno Python. Cómo configurarlo para servir tu API Flask. Cómo crear una infraestructura con varios contenedores corriendo instancias idénticas. Cómo exponer todo esto a internet a través de Nginx con balanceo de carga. Al final tendrás una arquitectura estable, escalable y fácil de replicar.\n","permalink":"http://localhost:1313/Servidor_WSGI/introduccion/","summary":"\u003cp\u003eBienvenido a la documentación del proyecto \u003cstrong\u003eTicTacToe API\u003c/strong\u003e, un sistema que combina:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFlask + Waitress\u003c/strong\u003e como servidor backend.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDocker + Docker Compose\u003c/strong\u003e para encapsular la aplicación.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNginx\u003c/strong\u003e como reverse proxy y balanceador de carga.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHugo\u003c/strong\u003e para documentar todo el proceso.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEl objetivo de este proyecto es ejecutar una API de forma escalable desde múltiples dispositivos, aprovechando la potencia de Docker y la estabilidad de Waitress como servidor WSGI.\u003c/p\u003e\n\u003cp\u003eAquí aprenderás:\u003c/p\u003e","title":"Introducción"}]